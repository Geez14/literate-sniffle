{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutliclass Support vector Machine loss\n",
    "\n",
    "> hingle loss or margine loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtr, Ytr), (Xte, Yte) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def unvectorizedSingleImage(\n",
    "    x: np.ndarray, y: np.ndarray, W: np.ndarray, bias: np.ndarray, delta: float = 1.0\n",
    "):\n",
    "    assert W.shape[1] == x.shape[0]\n",
    "    assert x.shape[1] == 1\n",
    "    assert y.shape[0] == 1\n",
    "\n",
    "    scores = W.dot(x) + bias  # score.shape is 10 x 1\n",
    "    D = scores.shape[0]\n",
    "    correct_class_score = scores[y]\n",
    "    loss_i = 0.0\n",
    "    for j in range(D):\n",
    "        if j == y:\n",
    "            continue\n",
    "        loss_i += max(0, scores[j] - correct_class_score + delta)\n",
    "    return loss_i\n",
    "\n",
    "\n",
    "def vectorizedSingleImage(\n",
    "    x: np.ndarray, y: np.ndarray, W: np.ndarray, bias: np.ndarray, delta: float = 1.0\n",
    "):\n",
    "    assert W.shape[1] == x.shape[0]\n",
    "    assert x.shape[1] == 1\n",
    "    assert y.shape[0] == 1\n",
    "\n",
    "    scores = W.dot(x) + bias  # scores.shape is 10 x 1\n",
    "    correct_class_score = scores[y]\n",
    "    margins = np.maximum(0, scores - correct_class_score + delta)\n",
    "    print(margins.shape)\n",
    "    margins[y] = 0\n",
    "    loss_i = np.sum(margins)\n",
    "    return loss_i\n",
    "\n",
    "\n",
    "def vectorizeMultipleImages(\n",
    "    X: np.ndarray, Y: np.ndarray, W: np.ndarray, bias: np.ndarray, delta: float = 1.0\n",
    "):\n",
    "    # assuming the X.shape = [image_quantity, h*w*channels]\n",
    "    \"\"\"shape of all_scores = W.shape[0], X.shape[1]\n",
    "    (10, n), n is number of images and 10 is features\n",
    "    \"\"\"\n",
    "    assert W.shape[1] == X.shape[0]\n",
    "    assert Y.shape[0] == X.shape[1]\n",
    "    Y = Y.reshape(-1)\n",
    "\n",
    "    counter = np.arange(Y.shape[0])\n",
    "    all_scores = W.dot(X) + bias  # all_scores.shape = 10 x n\n",
    "    # collect all the correct class scores from each example\n",
    "    \n",
    "    correct_class_scores = all_scores[Y, counter]\n",
    "    # np.maximum(0, a - b + 1)\n",
    "    margins = np.maximum(0, all_scores - correct_class_scores + delta)\n",
    "    # since multiclass SVM,taking 0 on the correct class to not over-infilate\n",
    "    margins[Y, counter] = 0\n",
    "\n",
    "    lossi = np.sum(margins, axis=0)\n",
    "    avg_lossi = np.mean(lossi)\n",
    "    return avg_lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "features = 10\n",
    "resolution = Xtr[0].shape[0]*Xtr[0].shape[1]*Xtr[0].shape[2]\n",
    "W = np.random.randn(features, resolution)\n",
    "bias = np.random.randn(features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(96991.26528102501)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Xtr[0].reshape(resolution, -1)\n",
    "y = Ytr[0]\n",
    "# single image test @passed\n",
    "# multi image test @passed\n",
    "# unvectorizedSingleImage(x, y, W, bias), vectorizedSingleImage(x, y, W, bias), \n",
    "vectorizeMultipleImages(x, y, W, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.5800000000000018)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.array([[0.01, -0.05, 0.1, 0.05], [0.7, 0.2, 0.05, 0.16], [0.0, -0.45, -0.2, 0.03]])\n",
    "x = np.array([-15, 22, -44, 56]).reshape(-1, 1)\n",
    "y = np.array([2])\n",
    "bias = np.array([0.0, 0.2, -0.3]).reshape(-1, 1)\n",
    "vectorizedSingleImage(x, y, W, bias, delta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = -log(normalize_probabilities)\n",
    "\n",
    "def L(X, Y, W, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
